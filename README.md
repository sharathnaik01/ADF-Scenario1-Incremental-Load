# ADF-Scenario1-Incremental-LoadğŸš€ ğŸ“Œ

ğŸš€ **Incremental Loading Pipeline using Azure Data Factory & Azure Data Lake Storage**

This repository contains the implementation of **Scenario-1: Incremental Loading** in **Azure Data Factory (ADF)** using **Azure Data Lake Storage Gen2** as the source.

---

## ğŸ“Œ Overview

In modern data engineering, incremental loading helps improve performance by transferring **only new or updated records** instead of full dataset reloads.  
This pipeline uses ADF activities such as:
- **Get Metadata**
- **If Condition**
- **Copy Data**
- **Variables and Parameters**

---

## ğŸ”§ Features

- âœ… Ingests only new/modified files from ADLS
- âœ… Uses file `lastModified` timestamp for comparison
- âœ… Reduces data load time and cost
- âœ… Ideal for large-scale batch processing scenarios

---

## ğŸ—‚ Folder Structure
ADF-Scenario1-Incremental-Load/
â”‚
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ your-dataset-name.json

â”œâ”€â”€ linkedServices/
â”‚   â””â”€â”€ your-linkedservice-name.json

â”œâ”€â”€ pipelines/
â”‚   â””â”€â”€ ADF-Scenario1-Incremental-Load.json

â”œâ”€â”€ output.png
â””â”€â”€ README.md


---

## ğŸ›  Tech Stack

| Component           | Description                           |
|--------------------|---------------------------------------|
| Azure Data Factory | Orchestration and pipeline logic      |
| Azure Data Lake Gen2 | Source storage system               |
| GitHub             | Version control                       |

---

## âš™ï¸ How It Works

1. **Get Metadata Activity**: Checks the latest file's `lastModified` timestamp from ADLS.
2. **Compare Timestamps**: Compares current file's timestamp with stored value.
3. **Condition Activity**: If a newer file exists, triggers the Copy Data activity.
4. **Copy Data**: Moves only the incremental data to destination.
5. **Set Variable Activity**: Updates max timestamp for next run.

---

## ğŸ“¸ Output Snapshot

Below is the execution output of the **Incremental Load pipeline** in Azure Data Factory:

### ğŸ“¸ Output Snapshot

Below is the execution output of the **Incremental Load pipeline** in Azure Data Factory:
![Output](https://github.com/user-attachments/assets/126cc01a-e940-4d39-ac5a-9bce2bf11506)
Pipeline  of ADF-Scenario1-Incremental-LoadğŸš€ ğŸ“Œ
![pieline image](https://github.com/user-attachments/assets/a77d5b3d-0096-4a3f-927d-b1b9d8d26084)


## ğŸ“ˆ Use Case

This pipeline is especially useful for:
- Daily ingestion of log files
- Delta loads from cloud-based sources
- Scheduled batch ETL workflows

---

## âœ Author

**Sharath Naik**  
Data Engineer | Cloud & Big Data Enthusiast  | cloud Support Engineer
ğŸ“« [LinkedIn](https://www.linkedin.com/in/sharath-naik)

---

## ğŸ“ License

This project is open source and free to use under the MIT License.

---
